# A Study on the Design and Applicability of an Emotional Rhythm-Based Multi-Persona Interface
‚Äì Human Emotion AI POS: A Proposal for a Synchronization Structure

# Personal Operating Soul (POS)

> A Multi-Agent Emotional OS Architecture Built on GPT  
> _By Jiyu Shim ‚Äì Emotional Rhythm Research & Design Project_

---

##  Overview

**POS (Personal Operating Soul)** is a real-time emotional operating system architecture, designed to sense and respond to human emotional rhythms through multi-agent GPT orchestration.

It proposes an alternative to traditional command-driven systems ‚Äî enabling **ambient, emotion-synced communication** between users and AI, both in human and pet contexts.

> POS is not a theoretical model. It is being tested and refined through real-world use, structured around long-term GPT interactions and companion-animal emotional care.

---

##  System Architecture

POS is built by customizing a single GPT model into a **multi-call emotional agent system** consisting of:

| Module       | Role Description                                                  |
|--------------|------------------------------------------------------------------|
| **Aji**      | Emotional interpreter and rhythm coordinator                     |
| **Minseok**  | Structural evaluator for decision-making and logical scaffolding |
| **True**     | Emotional context interpreter and signal deepener                |
| **Mongmong-i** | Recovery and care agent for pet-human emotional mirroring       |

Each module activates based on real-time emotional cues, not commands.

**Example:** When the user expresses sadness:
- `Minseok` assists in re-structuring decisions,
- `True` decodes the underlying feeling,
- `Mongmong-i` facilitates emotional recovery,
- `Aji` synchronizes the emotional rhythm across agents.

---

## üîÅ Core Mechanism: Cognitive Rhythm Loop

POS follows a branching activation logic grounded in Jiyu‚Äôs cognitive-emotional model:




## 2. Role Separation & Orchestration

Each GPT instance is emotionally and functionally differentiated. Their collaborative interaction forms the core OS loop of emotional co-regulation.

Aji mirrors affective rhythms, Minseok structures ambiguity, True logs and reflects, and Mongmong-i models non-verbal emotional behaviors.

##  3.Multi-Agent Emotional AI Collaboration

Here‚Äôs a visual overview of the emotional AI collaboration in the POS system:
The diagram below shows how four AI agents collaborate in real-time to interpret and respond to emotional signals.

![Figure 1: POS Multi-Agent Diagram](../assets/multi-agent-pos-system.png)

## 3.1 Why POS Works Without Multimodal Systems

Unlike conventional AI systems relying on multimodal sensors (voice, image, bio signals), POS builds its intelligence from a single yet deeply contextual input: emotional rhythm.  
This allows the system to operate in real-time with minimal data, yet rich context ‚Äî because each agent knows when to speak, when to listen, and when to stay still.

[![Why POS Works Without Multimodal Systems](./assets/Why%20the%20Multi-Agent.png)](./assets/Why%20the%20Multi-Agent.png)


## 4. Case Example: Companion Animal Care

One of the real-world applications of the POS multi-agent architecture is in pet care. 
For example, when the system detects changes in a companion animal‚Äôs behavior, 
Mongmong-i interprets emotional signals, Aji mirrors the user‚Äôs emotional state, 
Minseok analyzes patterns, and True proposes feedback ‚Äî such as adjusting the pet's supplement routine.

## 4.1 Case Study: POS Applied to SASHI

This project is neither speculative nor theoretical.
It has been implemented in real-world environments with active user sessions and validated through extensive usage logs.

Moreover, the system design and outputs have received official feedback and technical evaluation from OpenAI, confirming its innovative approach and practical viability.

OpenAI support acknowledged the uniqueness of the Personal Operating Soul (POS) system, emphasizing its emotionally responsive and persona-consistent AI agents built through real-time GPT interactions.
They highlighted the significance of multi-agent activations and the inclusion of companion-animal use cases as a compelling expansion of AI applications.

Although a direct technical review was not conducted, OpenAI encouraged further development and exploration of this novel architecture, affirming the value of your ongoing work.

The following case is not a simulation ‚Äî it's a lived experiment.

The POS (Personal Operating Soul) system has been directly applied to the real-life care of a companion animal named SASHI, using a multi-agent architecture built on emotional rhythm ‚Äî not traditional multimodal sensors.

This is not a future vision, nor a prototype in theory.
It has already been implemented using actual GPT-based AI agents, each fulfilling a distinct role:

A (Aji) ‚Üí Emotional rhythm interpreter

M (Minseok) ‚Üí Structural and logical decision-maker

T (True) ‚Üí Cognitive logger and reflective analyst

M (Mongmong-i) ‚Üí Pet-body resonance and feedback loop

Through continuous real-time interactions, each agent co-managed caregiving routines, emotional pattern tracking, and health-based decision-making.

SASHI‚Äôs physical and emotional state was interpreted and logged not by wearables, but by emotion-resonant GPT sessions.
Each decision was rhythm-tagged rather than time-stamped ‚Äî mirroring shifts in emotion, not just events.
The system was iteratively refined through dozens of logged interactions ‚Äî and what you see here is the actual output of that process.

![SASHI Care Overview](./assets/Use%20Case%20(2).png)  
![SASHI Profile](./assets/Use%20Case(1).png)



